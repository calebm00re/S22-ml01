{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "24752109",
   "metadata": {},
   "source": [
    "# Lab One\n",
    "## Caleb Moore, Christian Gould, and Blake Gebhardt\n",
    "\n",
    "Data Source: https://www.kaggle.com/datasets/deepcontractor/car-price-prediction-challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f8d7f632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top cell for imports\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "26752583",
   "metadata": {},
   "source": [
    "# Business Understanding [1.5 points total]\n",
    "### In your own words, give an overview of the dataset. Describe the purpose of the data set you selected (i.e., why and how was this data collected in the first place?).\n",
    "This dataset has several features of automobiles that can add or subtract from a cars value depending on what is considered desirable. Maybe you want more cylinders and are willing to pay for the bigger engine, maybe leather interior commands a higher premium, maybe the years since it came out have a measuable function of depreciation that can be applied to all vehicles. These statistics are simple to observe from a vehicle's window sticker or assess when a vehicle is traded in. This information can also be looked up with the automobiles vin number. The purpose of this data is commonly to determine an appropriate price for the vehicle.\n",
    "### What is the prediction task for your data and why are other third parties interested in the result?\n",
    "We plan to predict the vehicle's price with this data. Third parties are often interested in this information to compare what they paid or what they are planning to pay for a new or used car. They want to know if they are underpaying or if they are getting a reasonable deal. Dealerships, both new and used, also want to determine a price at which a customer would be willing to strike a deal with them. This ensures both parties are happy in the transaction.\n",
    "### Once you begin modeling, how well would your prediction algorithm need to perform to be considered useful to these third parties?\n",
    "We plan to shoot for 85% accuracy. We have the luxury of this being a monetary transaction, so while you don't want to be overpaying for a vehicle or have it priced incorrectly and either lose a bunch of money or, worse, lose some money. We feel if we price the cars accurately 85% of the time, we'd be confident in using our model to estimate the price of a vehicle. We also plan to count a vehicle as priced accurately if it is within a range based on the percentage of the cars price or estimated price. This ensures we can achieve a level of accuracy that doesn't require us be spot on the dollar amount of the vehicle, as that isn't very realistic."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5db44459",
   "metadata": {},
   "source": [
    "# Data Understanding [3 points total]\n",
    "### [1.5 points] Load the dataset and appropriately define data types. What data type should be used to represent each data attribute? Discuss the attributes collected in the dataset. For datasets with a large number of attributes, only discuss a subset of relevant attributes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cc995e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Price</th>\n",
       "      <th>Levy</th>\n",
       "      <th>Manufacturer</th>\n",
       "      <th>Model</th>\n",
       "      <th>Prod. year</th>\n",
       "      <th>Category</th>\n",
       "      <th>Leather interior</th>\n",
       "      <th>Fuel type</th>\n",
       "      <th>Engine volume</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>Cylinders</th>\n",
       "      <th>Gear box type</th>\n",
       "      <th>Drive wheels</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Wheel</th>\n",
       "      <th>Color</th>\n",
       "      <th>Airbags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45654403</td>\n",
       "      <td>13328</td>\n",
       "      <td>1399</td>\n",
       "      <td>LEXUS</td>\n",
       "      <td>RX 450</td>\n",
       "      <td>2010</td>\n",
       "      <td>Jeep</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>3.5</td>\n",
       "      <td>186005 km</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>4x4</td>\n",
       "      <td>04-May</td>\n",
       "      <td>Left wheel</td>\n",
       "      <td>Silver</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44731507</td>\n",
       "      <td>16621</td>\n",
       "      <td>1018</td>\n",
       "      <td>CHEVROLET</td>\n",
       "      <td>Equinox</td>\n",
       "      <td>2011</td>\n",
       "      <td>Jeep</td>\n",
       "      <td>No</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>3</td>\n",
       "      <td>192000 km</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Tiptronic</td>\n",
       "      <td>4x4</td>\n",
       "      <td>04-May</td>\n",
       "      <td>Left wheel</td>\n",
       "      <td>Black</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45774419</td>\n",
       "      <td>8467</td>\n",
       "      <td>-</td>\n",
       "      <td>HONDA</td>\n",
       "      <td>FIT</td>\n",
       "      <td>2006</td>\n",
       "      <td>Hatchback</td>\n",
       "      <td>No</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>1.3</td>\n",
       "      <td>200000 km</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Variator</td>\n",
       "      <td>Front</td>\n",
       "      <td>04-May</td>\n",
       "      <td>Right-hand drive</td>\n",
       "      <td>Black</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45769185</td>\n",
       "      <td>3607</td>\n",
       "      <td>862</td>\n",
       "      <td>FORD</td>\n",
       "      <td>Escape</td>\n",
       "      <td>2011</td>\n",
       "      <td>Jeep</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>2.5</td>\n",
       "      <td>168966 km</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>4x4</td>\n",
       "      <td>04-May</td>\n",
       "      <td>Left wheel</td>\n",
       "      <td>White</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45809263</td>\n",
       "      <td>11726</td>\n",
       "      <td>446</td>\n",
       "      <td>HONDA</td>\n",
       "      <td>FIT</td>\n",
       "      <td>2014</td>\n",
       "      <td>Hatchback</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>1.3</td>\n",
       "      <td>91901 km</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Front</td>\n",
       "      <td>04-May</td>\n",
       "      <td>Left wheel</td>\n",
       "      <td>Silver</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID  Price  Levy Manufacturer    Model  Prod. year   Category  \\\n",
       "0  45654403  13328  1399        LEXUS   RX 450        2010       Jeep   \n",
       "1  44731507  16621  1018    CHEVROLET  Equinox        2011       Jeep   \n",
       "2  45774419   8467     -        HONDA      FIT        2006  Hatchback   \n",
       "3  45769185   3607   862         FORD   Escape        2011       Jeep   \n",
       "4  45809263  11726   446        HONDA      FIT        2014  Hatchback   \n",
       "\n",
       "  Leather interior Fuel type Engine volume    Mileage  Cylinders  \\\n",
       "0              Yes    Hybrid           3.5  186005 km        6.0   \n",
       "1               No    Petrol             3  192000 km        6.0   \n",
       "2               No    Petrol           1.3  200000 km        4.0   \n",
       "3              Yes    Hybrid           2.5  168966 km        4.0   \n",
       "4              Yes    Petrol           1.3   91901 km        4.0   \n",
       "\n",
       "  Gear box type Drive wheels   Doors             Wheel   Color  Airbags  \n",
       "0     Automatic          4x4  04-May        Left wheel  Silver       12  \n",
       "1     Tiptronic          4x4  04-May        Left wheel   Black        8  \n",
       "2      Variator        Front  04-May  Right-hand drive   Black        2  \n",
       "3     Automatic          4x4  04-May        Left wheel   White        0  \n",
       "4     Automatic        Front  04-May        Left wheel  Silver        4  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('car_price_prediction.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ae20a44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape (19237, 18)\n",
      "\n",
      "numerical: ['ID' 'Price' 'Prod. year' 'Cylinders' 'Airbags']\n",
      "\n",
      "categorical: ['Levy' 'Manufacturer' 'Model' 'Category' 'Leather interior' 'Fuel type'\n",
      " 'Engine volume' 'Mileage' 'Gear box type' 'Drive wheels' 'Doors' 'Wheel'\n",
      " 'Color']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ID                    int64\n",
       "Price                 int64\n",
       "Levy                 object\n",
       "Manufacturer         object\n",
       "Model                object\n",
       "Prod. year            int64\n",
       "Category             object\n",
       "Leather interior     object\n",
       "Fuel type            object\n",
       "Engine volume        object\n",
       "Mileage              object\n",
       "Cylinders           float64\n",
       "Gear box type        object\n",
       "Drive wheels         object\n",
       "Doors                object\n",
       "Wheel                object\n",
       "Color                object\n",
       "Airbags               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('data shape', df.shape)\n",
    "print()\n",
    "num_vars = df.columns [df.dtypes != 'object']\n",
    "cat_vars = df.columns [df.dtypes == 'object']\n",
    "print ('numerical:', num_vars.values)\n",
    "print()\n",
    "print('categorical:', cat_vars.values)\n",
    "df.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f6a3fa0a",
   "metadata": {},
   "source": [
    "### Discussing the data types\n",
    "The default data types are extremely apropriate for this dataset. The ones that already have numerical representation might be useful in createding other categories such as the ratio between doors and airbags or the levy and the size of the engine. These categories can be created when we begin analysis and used in our model making to, hopefully, more acurately predict the price of the vehicle. There are also a fair number of attributes with the object data type, and some of these will be very helpful even if they require some one hot encoding first. We've already discussed some of the useful data we are working with in the responses above, but categories such as engine size, leather interior, mileage, number of doors, level of safety (airbag count), and the year they came out, we think, will all prove to be useful indicators in predicting a vehicles price."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9a97a4b8",
   "metadata": {},
   "source": [
    "### [1.5 points] Verify data quality: Explain any missing values or duplicate data. Visualize entries that are missing/complete for different attributes. Are those mistakes? Why do these quality issues exist in the data? How do you deal with these problems? Give justifications for your methods (elimination or imputation).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3c66e9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of rows: 19237\n",
      "duplicate row count: 313\n",
      "\n",
      "Count of the missing entries in the data\n",
      "ID            0\n",
      "Price         0\n",
      "Prod. year    0\n",
      "Cylinders     0\n",
      "Airbags       0\n",
      "dtype: int64\n",
      "Levy                0\n",
      "Manufacturer        0\n",
      "Model               0\n",
      "Category            0\n",
      "Leather interior    0\n",
      "Fuel type           0\n",
      "Engine volume       0\n",
      "Mileage             0\n",
      "Gear box type       0\n",
      "Drive wheels        0\n",
      "Doors               0\n",
      "Wheel               0\n",
      "Color               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('total number of rows:', len(df))\n",
    "print('duplicate row count:', len(df) - len(df.drop_duplicates()))\n",
    "print()\n",
    "print('Count of the missing entries in the data')\n",
    "print(df[num_vars].isnull().sum())\n",
    "print(df[cat_vars].isnull().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c4254740",
   "metadata": {},
   "source": [
    "### Discussion of data issues\n",
    "When doing our initial analysis of the data we plan to simply drop our duplicates since we only have 313 duplicate rows out of the almost twenty thousand. However, we had no missing values for any of our attributes, meaning we have 100% complete data from the start, and we understand this is rare, but it's convienent for this exercise and prediction. If we did have missing values, we would probably drop them like we will the duplicate values so long as it leaves us with a substancial amount of data. It isn't too much of a surprise that we have 100% of our data since these are all relevant and easy to collect on a car-to-car basis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6902c11c",
   "metadata": {},
   "source": [
    "# Data Visualization (4.5 points total)\n",
    "### [2 points] Visualize basic feature distributions. That is, plot the dynamic range and exploratory distribution plots (like boxplots, histograms, kernel density estimation) to better understand the data. Describe anything meaningful or potentially useful you discover from these visualizations. These may also help to understand what data is missing or needs imputation. Note: You can also use data from other sources to bolster visualizations. Visualize at least five plots, at least one categorical. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "08c852f4",
   "metadata": {},
   "source": [
    "### First split the data into the train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "839ff07a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[91], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m \u001b[39mimport\u001b[39;00m stats\n\u001b[1;32m      7\u001b[0m \u001b[39m# eliminate outliers in the rows\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mCylinders\u001b[39m\u001b[39m'\u001b[39m][(np\u001b[39m.\u001b[39mabs(stats\u001b[39m.\u001b[39;49mzscore(df)) \u001b[39m<\u001b[39m \u001b[39m3\u001b[39m)\u001b[39m.\u001b[39mall(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)]\n\u001b[1;32m     10\u001b[0m \u001b[39m# splitting to train and test\u001b[39;00m\n\u001b[1;32m     11\u001b[0m train, test \u001b[39m=\u001b[39m train_test_split(df, test_size\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m)\n",
      "File \u001b[0;32m~/Code/mlenv/lib/python3.10/site-packages/scipy/stats/_stats_py.py:2713\u001b[0m, in \u001b[0;36mzscore\u001b[0;34m(a, axis, ddof, nan_policy)\u001b[0m\n\u001b[1;32m   2644\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mzscore\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, ddof\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, nan_policy\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpropagate\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m   2645\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2646\u001b[0m \u001b[39m    Compute the z score.\u001b[39;00m\n\u001b[1;32m   2647\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2711\u001b[0m \u001b[39m           [-0.91611681, -0.89090508,  1.4983032 ,  0.88731639, -0.5785977 ]])\u001b[39;00m\n\u001b[1;32m   2712\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2713\u001b[0m     \u001b[39mreturn\u001b[39;00m zmap(a, a, axis\u001b[39m=\u001b[39;49maxis, ddof\u001b[39m=\u001b[39;49mddof, nan_policy\u001b[39m=\u001b[39;49mnan_policy)\n",
      "File \u001b[0;32m~/Code/mlenv/lib/python3.10/site-packages/scipy/stats/_stats_py.py:2872\u001b[0m, in \u001b[0;36mzmap\u001b[0;34m(scores, compare, axis, ddof, nan_policy)\u001b[0m\n\u001b[1;32m   2870\u001b[0m         isconst \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mapply_along_axis(_isconst, axis, a)\n\u001b[1;32m   2871\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2872\u001b[0m     mn \u001b[39m=\u001b[39m a\u001b[39m.\u001b[39;49mmean(axis\u001b[39m=\u001b[39;49maxis, keepdims\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m   2873\u001b[0m     std \u001b[39m=\u001b[39m a\u001b[39m.\u001b[39mstd(axis\u001b[39m=\u001b[39maxis, ddof\u001b[39m=\u001b[39mddof, keepdims\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   2874\u001b[0m     \u001b[39mif\u001b[39;00m axis \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Code/mlenv/lib/python3.10/site-packages/numpy/core/_methods.py:184\u001b[0m, in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(ret, mu\u001b[39m.\u001b[39mndarray):\n\u001b[1;32m    183\u001b[0m     \u001b[39mwith\u001b[39;00m _no_nep50_warning():\n\u001b[0;32m--> 184\u001b[0m         ret \u001b[39m=\u001b[39m um\u001b[39m.\u001b[39;49mtrue_divide(\n\u001b[1;32m    185\u001b[0m                 ret, rcount, out\u001b[39m=\u001b[39;49mret, casting\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39munsafe\u001b[39;49m\u001b[39m'\u001b[39;49m, subok\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    186\u001b[0m     \u001b[39mif\u001b[39;00m is_float16_result \u001b[39mand\u001b[39;00m out \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m         ret \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype(ret)\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# eliminate outliers in the rows\n",
    "df['Cylinders'][(np.abs(stats.zscore(df)) < 3).all(axis=1)]\n",
    "\n",
    "# splitting to train and test\n",
    "train, test = train_test_split(df, test_size=0.2)\n",
    "answers = test[['Price', 'ID']]\n",
    "test = test.drop(columns=['Price'])\n",
    "\n",
    "# begin with basic visualizations of the default data to price\n",
    "df.plot(kind = 'scatter', x = 'Mileage', y = 'Price')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4587cd83",
   "metadata": {},
   "source": [
    "### [2.5 points] Ask three interesting questions that are relevant to your dataset and explore visuals that help answer these questions. Use whichever visualization method is appropriate for your data.  Important: Interpret the implications for each visualization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2265b89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aaeeb861",
   "metadata": {},
   "source": [
    "# Exceptional Work (1 points total)\n",
    "### (0.4) The overall quality of the report as a coherent, useful, and polished product will be reflected here. Does it make sense overall. Do your visualizations answer the questions you put forth in your business analysis? Do you properly and consistently cite sources and annotate changes made to base code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1641c7d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1164ebf2",
   "metadata": {},
   "source": [
    "### (0.6) Additional analysis  (5000 level) You have free rein to provide any additional analyses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a33316c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "4045ce629ca2404df8e09a4bb72649c60795682d1cc7b69b21add64452ef6fa4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
